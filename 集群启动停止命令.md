Apache ZooKeeper

```shell
# 启动
sh startZk.sh

# 停止
sh stopZk.sh
```

Apache Hadoop集群

```shell
# 启动所有
start-all.sh

# 停止所有
stop-all.sh

# 启动HDFS
start-dfs.sh

# 停止HDFS
stop-dfs.sh

# 启动yarn
start-yarn.sh

# 停止yarn
stop-yarn.sh
```

Apache Hive

```shell
# 前台启动  关闭ctrl+c
/export/server/apache-hive-3.1.2-bin/bin/hive --service metastore

# 前台启动开启debug日志
/export/server/apache-hive-3.1.2-bin/bin/hive --service metastore --hiveconf hive.root.logger=DEBUG,console  

# 后台启动 进程挂起  关闭使用jps+ kill -9
nohup /export/server/apache-hive-3.1.2-bin/bin/hive --service metastore &

# 第一代客户端Hive Client
/export/server/apache-hive-3.1.2-bin/bin/hive

# 第二代客户端Hive Beeline
nohup /export/server/apache-hive-3.1.2-bin/bin/hive --service metastore &
nohup /export/server/apache-hive-3.1.2-bin/bin/hive --service hiveserver2 &
# 在node3上使用beeline客户端进行访问
[root@node3 ~]# /export/server/hive/bin/beeline
# 连接
beeline> ! connect jdbc:hive2://node1:10000
Connecting to jdbc:hive2://node1:10000
Enter username for jdbc:hive2://node1:10000: root
Enter password for jdbc:hive2://node1:10000: 
Connected to: Apache Hive (version 3.1.2)
Driver: Hive JDBC (version 3.1.2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
0: jdbc:hive2://node1:10000> 
```

Apache Spark

```shell
# 启动hive-metastore
start-metastore.sh

# 启动Thrift JDBC/ODBC server服务
/export/server/spark-local/sbin/start-thriftserver.sh \
--hiveconf hive.server2.thrift.port=10000 \
--hiveconf hive.server2.thrift.bind.host=node1.itcast.cn \
--master local[2] \
--conf spark.sql.shuffle.partitions=2
```

HBase

```bash
# 启动HBase集群服务，node1上执行
hbase-daemon.sh start master
hbase-daemons.sh start regionserver
```

